from flask import Flask, render_template, Response
import cv2
from deepface import DeepFace
import traceback

app = Flask(__name__)

# Load Haar cascade classifier for face detection
face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

# Function to capture video stream, detect faces, and analyze emotions
def detect_faces():
    # Open the video stream
    video = cv2.VideoCapture(0)

    # Check if the video stream is opened successfully
    if not video.isOpened():
        print("Error: Unable to open video stream.")
        return

    try:
        # Loop to capture frames from the video stream
        while True:
            # Capture frame-by-frame
            check, frame = video.read()

            # Check if frame is read correctly
            if not check:
                print("Error: Unable to read frame.")
                break

            # Convert frame to grayscale for face detection
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Detect faces using Haar cascade classifier
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

            # Analyze emotions for each detected face
            for x, y, w, h in faces:
                try:
                    # Draw rectangle around the face
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)

                    # Extract region of interest (ROI) for emotion analysis
                    roi_gray = gray[y:y+h, x:x+w]

                    # Analyze emotions using DeepFace
                    analyze = DeepFace.analyze(roi_gray, actions=['emotion'], enforce_detection=False)
                    result = analyze[0]

                    # Display dominant emotion on the frame
                    emotion = result['dominant_emotion']
                    cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

                except Exception as e:
                    print("Error occurred during emotion analysis:")
                    print(traceback.format_exc())

            # Encode frame as JPEG image
            ret, jpeg = cv2.imencode('.jpg', frame)

            # Check if frame is encoded correctly
            if not ret:
                print("Error: Unable to encode frame.")
                break

            # Yield the encoded frame as byte data
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')

    finally:
        # Release the video stream
        video.release()

# Route for the live video feed
@app.route('/video_feed')
def video_feed():
    # Return the response generated by the detect_faces function
    return Response(detect_faces(), mimetype='multipart/x-mixed-replace; boundary=frame')

# Route for the index page
@app.route('/')
def index():
    return render_template('index.html')

if __name__ == '__main__':
    app.run(debug=True)
